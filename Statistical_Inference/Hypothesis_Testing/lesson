- Class: meta
  Course: Statistical_Inference
  Lesson: Hypothesis_Testing
  Author: Swirl Coders
  Type: Coursera
  Organization: Johns Hopkins Bloomberg School of Public Health
  Version: 2.2.0

- Class: text
  Output: "Hypothesis_Testing. (Slides for this and other Data Science courses may be found at github https://github.com/DataScienceSpecialization/courses/. If you care to use them, they must be downloaded as a zip file and viewed locally. This lesson corresponds to 06_Statistical_Inference/09_HT.)"

- Class: text
  Output: In this lesson, as the name suggests, we'll discuss hypothesis testing which is concerned with making decisions using data.

- Class: text
  Output: An important concept in hypothesis testing is the NULL hypothesis, usually denoted as H_0. This is the hypothesis that represents the status_quo and is assumed true. Statistical evidence is required to reject it in favor of a research or alternative hypothesis. 

- Class: text
  Output: We'll consider the motivating example from the slides. A respiratory disturbance index (RDI) of more than 30 events / hour is considered evidence of severe sleep disordered breathing (SDB). Suppose that in a sample of 100 overweight subjects with other risk factors for (SDB) at a sleep clinic, the mean RDI (X') was 32 events / hour with a standard deviation (s) of 10 events / hour.

- Class: text
  Output: We might want to test the null hypothesis H_0 that says mu = 30. Our alternative hypothesis H_a is that mu>30. Here mu is the population mean RDI.
 
- Class: text
  Output: So we have two competing hypotheses, H_0 and H_a, of which we'll have to pick one (using statistical evidence of course). That means we have four possible outcomes determined by what really is (truth) and which hypothesis we accept. Two of the outcomes are correct and two are errors. 

- Class: mult_question
  Output: Which of the following outcomes is correct?
  AnswerChoices: H_0 is TRUE and we reject it; H_a is TRUE and we accept it; H_0 is FALSE and we accept it; H_a is FALSE and we accept it
  CorrectAnswer: H_a is TRUE and we accept it
  AnswerTests: omnitest(correctVal='H_a is TRUE and we accept it')
  Hint: It's always better to ACCEPT the TRUTH.

- Class: mult_question
  Output: Which of the following outcomes is an error?
  AnswerChoices: H_0 is TRUE and we reject it; H_a is TRUE and we accept it; H_0 is FALSE and we reject it; H_a is FALSE and we reject it
  CorrectAnswer: H_a is TRUE and we accept it
  AnswerTests: omnitest(correctVal='H_a is TRUE and we accept it')
  Hint: It's always a mistake to REJECT the TRUTH.

- Class: text
  Output: So it's correct to accept a true hypothesis or reject a false one. Pretty clear, right?

- Class: text
  Output: The errors are also clear - rejecting a true hypothesis or accepting a false one. 

- Class: text
  Output: We distinguish between these two errors. A Type I error REJECTS a TRUE null hypothesis H_0 and a Type II error ACCEPTS a FALSE null hypothesis H_0. In our hypothesis testing we'll set the probability of making a Type I error small. 

- Class: mult_question
  Output: But we can see that the probabilities of making these errors is related. If you decrease the probability of making a Type I error (rejecting a true hypothesis), you increase the probability of making a Type II error (accepting a false one) and vice versa. As in the slides, we'll consider an American court of law. The null hypothesis is that the defendant is innocent. If an innocent man is convicted what type of error is this?
  AnswerChoices: Type I; Type II
  CorrectAnswer: Type I
  AnswerTests: omnitest(correctVal='Type I')
  Hint: You're rejecting a true null hypothesis. Recall that a Type II error accepts a false null hypothesis.

- Class: mult_question
  Output: You might send the innocent man to jail by rejecting H_0. Suppose a guilty person is not convicted. What type of error is this?
  AnswerChoices: Type I; Type II
  CorrectAnswer: Type II
  AnswerTests: omnitest(correctVal='Type II')
  Hint: You're accepting a null hypothesis (innocence) that is false. Recall that a Type I error rejects the truth.

- Class: text
  Output: Back to sleep (example)! A reasonable strategy would reject the null hypothesis if our sample mean X' was larger than some constant, say C. Typically, C is chosen so that the probability of a Type I error, alpha, is .05 (or some other relevant constant). Many papers using statistical inference use .05 as a standard level of rejection.

- Class: text
  Output:  This means that  alpha, the Type I error rate, is the probability of rejecting the null hypothesis when, in fact, the null hypothesis is correct. We don't want alpha too low because then we would never reject the null hypothesis even if it's false.

- Class: cmd_question
  Output: Recall that the standard error of a sample mean is given by the formula s/sqrt(n). Recall in our sleep example we had a sample of 100 subjects, our mean RDI (X') was 32 events / hour with a standard deviation (s) of 10 events / hour. What is the standard error of the mean?
  CorrectAnswer: 1
  AnswerTests: equiv_val(1)
  Hint: Divide s by sqrt(n).

- Class: text
  Output: Under H_0, X' is normally distributed with mean mu=30 and variance 1. We want to choose the constant C so that the probability that X is greater than C given H_0 is 5%. That is, P(X > C| H_0) is 5%. Sound familiar? 

- Class: figure
  Output: Here's a plot to show what we mean. The shaded portion represents 5% of the area under the curve and those X values in it are those for which the probability that X>C is 5%. 
  Figure: conf_5pct.R
  FigureType: new

- Class: mult_question
  Output: The shown curve has a standard deviation of 2. The shaded portion represents 5% of the area under the density curve. Which expression represents the smallest value X for which the area is shaded?
  AnswerChoices: qnorm(.95,sd=2); qnorm(.95); dnorm(.95,sd=2); qnorm(.975,sd=2)
  CorrectAnswer: qnorm(.95,sd=2)
  AnswerTests: omnitest(correctVal='qnorm(.95,sd=2)')
  Hint: The shading begins at the 95th percentile and the smallest value X for which the area is shaded represents the 95th quantile. We have to tell qnorm the standard deviation of the normal.

- Class: text
  Output: The 95th percentile of a standard normal distribution is 1.645 standard deviations from the mean, so in our example we have to set C to be 1.645 standard deviations MORE than our hypothesized mean of 30. If C = 30 + 1 * 1.645 = 31.645 then if our sample mean X' is greater than or equal to C, the probability that a sample from a normal distribution with mean 30, and variance 1 is larger than C is 5%.

- Class: text
  Output: So the rule "Reject H_0 when the sample mean X' >= 31.645" has the property that the probability of rejection H_0 when it is TRUE is 5% when the hypothesized mean mu=30, sigma=1 and n=100 as given in this example.

- Class: text
  Output: As you might expect, we can generalize the above result. Instead of computing a constant C as a cutpoint for accepting or rejecting the null hypothesis, we can simply compute a Z score, the number of standard deviations the sample mean is from the hypothesized mean. We can then  compare it to the specified quantile.

- Class: text
  Output: How do we do this? Compute the distance between the two means (32-30) and divide by the standard error of the mean, that is  (s/sqrt(n)). In this example the standard error is 10/sqrt(100)=1. The Z score is thus 2. 
The quantile is 1.645, so since 2>1.645 we can reject the null hypothesis. The general rule for rejection is if sqrt(n) * ( X' - mu) / s > Z_{1-alpha}.

- Class: text
  Output: Our test statistic is (X'-mu) / s/sqrt(n) which is standard normal.

- Class: mult_question
  Output: This means that our test statistic has what mean and standard deviation?
  AnswerChoices: 0 and 1; 1 and 0; 0 and 0; 1 and 1
  CorrectAnswer: 0 and 1
  AnswerTests: omnitest(correctVal='0 and 1')
  Hint: The standard normal is centered around 0 and has a standard deviation of 1.

- Class: text
  Output: Suppose our null hypothesis is that the population mean mu equals the value mu_0 and we set alpha=.05. This is the probability that we would reject H_0 if it were true. We can have several different alternative hypotheses.

- Class: text
  Output: Suppose our first alternative, H_a., is that mu < mu_0. We would reject H_0 (and accept H_a) when our sample mean is significantly less than mu_0. What do we mean by significant? It means that our test statistic  (X'-mu) / s/sqrt(n) is  less than Z_alpha, that is, more than 1.64 standard deviations to the left of the mean mu_0.

- Class: figure
  Output: Here's a plot to show what we mean. The shaded portion represents 5% of the area under the curve and those X values in it are those which are at least 1.64 standard deviations less than (to the left of) the mean. The probability of this is 5%. This means that we would reject a true null hypothesis, that mu=mu_0, with probability 5%.
  Figure: conf_5pct_left.R
  FigureType: new

- Class: mult_question
  Output: We already covered the alternative hypothesis H_a that mu > mu_0 but let's review it. We would reject H_0 (and accept H_a) when our sample mean is what?
  AnswerChoices: significantly greater than mu_0; significantly less than mu_0; equal to mu_0; huh?
  CorrectAnswer: significantly greater than mu_0
  AnswerTests: omnitest(correctVal='significantly greater than mu_0')
  Hint: If we accept H_a, that the true mu is greater than the H_0 value mu_0 we would want our sample mean to be greater the mu_0.

- Class: mult_question
  Output: This means that our test statistic (X'-mu) / s/sqrt(n) is what?
  AnswerChoices: at least 1.64 std dev greater than mu_0; at least 1.64 std dev less than mu_0; equal to mu_0; huh?
  CorrectAnswer: at least 1.64 std dev greater than mu_0
  AnswerTests: omnitest(correctVal='at least 1.64 std dev greater than mu_0')
  Hint: If we accept H_a, that the true mu is greater than the H_0 value mu_0 we would want our test statistic to be greater than 1.64 standard deviations from the mean.

- Class: figure
  Output: Here again is the plot to show what we mean. The shaded portion represents 5% of the area under the curve and those X values in it are those which are at least 1.64 standard deviations greater than (to the right of) the mean. The probability of this is 5%. This means that we would reject a true null hypothesis, that mu=mu_0, with probability  5%.
  Figure: conf_5pct_left.R
  FigureType: new

- Class: text
  Output: Finally, let's consider the alternative hypothesis H_a that mu is simply not equal to mu_0, the mean supposed in the null hypothesis.  We would reject H_0 (and accept H_a) when our sample mean is significantly different than mu_0. In this case it can be either less than OR greater than mu_0. Since we want to stick with a 5% rejection rate, we divide it in half and consider values at both tails, that is at the .025 and the .975 percentiles.  This means that our test statistic  (X'-mu) / s/sqrt(n) is  less than Z_(alpha/2) or greater than Z_(1-alpha/2).

- Class: figure
  Output: Here's the plot to show what we mean. The shaded portion represents 5% of the area under the curve but it's composed of two pieces, each of which contains 2.5% of the area under the curve. Those X values in the shaded portions are values which are at least 1.96 standard deviations away from the mean in either direction. The total probability of this is 5%. This means that we would reject a true null hypothesis, that mu=mu_0, with probability 5%.
  Figure: conf_5pct_left.R
  FigureType: new

- Class: text
  Output: Notice that we have fixed alpha to be low, so if we reject H_0, either it was FALSE (and hence our model is wrong and we are correct to reject it) OR H_0 is TRUE and we have made an error (Type I). The probability of this is 5%.  

- Class: text
  Output: Since our tests were based on alpha, the probability of a Type I error, we say that  we "fail to reject H_0" rather than we "accept $H_0$". H_0 could be true or we might not have enough data to reject it.

- Class: text
  Output: We have not fixed the probability of a type II error (accepting H_0 when it is false), which we call beta. The quantity 1-beta which is the probability of rejecting H_0 when it's false, POWER. This is used to determine appropriate sample sizes in experiments. Finally, note that statistical significance is not the same as scientific significance but it's complicated to distinguish between the two. 

- Class: mult_question
  Output: What do you think we call the region of test statistic values for which we reject H_0? 
  AnswerChoices: the rejection region; the shady tails; the abnormal region; the region of interest; the waggy tails
  CorrectAnswer: the rejection region
  AnswerTests: omnitest(correctVal='the rejection region')
  Hint: Which choice has the word 'reject' in it?
 
- Class: text
  Output: Note that so far we've been talking about NORMAL distributions and implicitly relying on the CENTRAL LIMIT THEOREM (CLT).

- Class: mult_question
  Output: Remember the CLT. For a distribution to be approximated by a normal what does the sample size have to be?
  AnswerChoices: large; small; abnormal; normal; 
  CorrectAnswer: large
  AnswerTests: omnitest(correctVal='large')
  Hint: As the sample size gets bigger the distribution looks normal.

- Class: text
  Output: No need to worry. If we don't have a large sample size, we can use the t distribution which conveniently uses the same test statistic (X'-mu) / s/sqrt(n) we used above.  That means that all the examples we just went through would work exactly the same EXCEPT instead of using NORMAL quantiles, we would use t quantiles and n-1 degrees of freedom. 

- Class: text
  Output: We said t distributions were very handy, didn't we?  

- Class: text
  Output: Let's go back to our sleep disorder example and suppose our sample size=16 (instead of 100). Our sample mean X'=32, the standard deviation s=10.  H_0 is that the true mean mu=30, and H_a is that mu>30. With this smaller sample size we need the t test, but our test statistic is computed the same way, namely (X'-mu)/(s/sqrt(n)) 

- Class: cmd_question
  Output: What is the value of the test statistic with sample size 16?
  CorrectAnswer: .8
  AnswerTests: equiv_val(.8)
  Hint: Type (32-30)/(10/4) at the command prompt.

- Class: cmd_question
  Output: How many degrees of freedom do we have under this new scenario?
  CorrectAnswer: 15
  AnswerTests: equiv_val(15)
  Hint: Recall that the number of degrees of freedom is one less than the sample size. Here the sample size is 16.

- Class: cmd_question
  Output: Under H_0, the probability that the test statistic is larger that the 95th percentile of the t distribution is 5%. Use the R function qt with the arguments .95 and the correct number of degrees of freedom.
  CorrectAnswer: qt(.95,15)
  AnswerTests: omnitest(correctExpr='qt(.95,15)')
  Hint: Type qt(.95,15) at the command prompt.

- Class: text
  Output: So the test statistic is within 1.64 standard deviations of the hypothesized mean, so we fail to reject H_0.

- Class: text
  Output: Now let's consider a two-sided test. Suppose that we would reject the null hypothesis if in fact the sample mean was too large or too small. That is, we want to test the alternative H_a that mu is not equal to 30. We will reject if the test statistic, 0.8, is either too large or too small.

- Class: text
  Output: As we discussed before, we want the probability of rejecting under the null to be 5%, split equally as 2.5% in the upper tail and 2.5% in the lower tail. Thus we reject if our test statistic is larger than qt(.975, 15) or smaller than qt(.025, 15).

- Class: mult_question
  Output: Do you expect qt(.975,15) to be bigger or smaller than qt(.95,15)?
  AnswerChoices: bigger; smaller
  CorrectAnswer: bigger
  AnswerTests: omnitest(correctVal='bigger')
  Hint: You're looking for a smaller area under the curve so that means the quantile will be farther out on the right tail so it should be bigger.

- Class: mult_question
  Output: Since the test statistic was smaller than qt(.95,15) will it be bigger or smaller than qt(.975,15)?
  AnswerChoices: bigger; smaller
  CorrectAnswer: smaller
  AnswerTests: omnitest(correctVal='smaller')
  Hint: If A<B and B<C it follows that A<C, right?

- Class: mult_question
  Output: Now to the left tail, qt(.025,15). What can we say about it?
  AnswerChoices: it's less than 0; it's greater than 0; it's bigger than qt(.975,15); we don't know anything about it
  CorrectAnswer: it's less than 0
  AnswerTests: omnitest(correctVal='it's less than 0')
  Hint: Any quantile of a percentile less than .5 will be less than 0 by the symmetry of the distribution.

- Class: mult_question
  Output: So the test statistic .8 failed both sides of the test. That means we ?
  AnswerChoices: fail to reject H_0; reject H_0; reject H_a; huh?
  CorrectAnswer: fail to reject H_0
  AnswerTests: omnitest(correctVal='fail to reject H_0')
  Hint: Again, the test statistic is close to the hypothesized mean so we fail to reject it. 

- Class: text
  Output: Bottom line here is if you fail to reject the one sided test, you know that you will fail to reject the two sided.

- Class: mult_question
  Output: Quick check. In the formula t=(X' - mu}/(s/sqrt(n)), if we replaced s by sigma the statistic t would be what?.
  AnswerChoices: the standard normal; the standard abnormal; the population variance; Huh?
  CorrectAnswer: the standard normal
  AnswerTests: omnitest(correctVal='the standard normal')
  Hint: With the replacement the formula should look familiar, like a standardized normal perhaps?

- Class: figure
  Output: To see what we mean, we've taken code from the slides, the function myplot, which takes the integer df as its input and plots the t distribution with df degrees of freedom. It also plots a standard normal distribution so you can see how they relate to one another. 
  Figure: tPlot.R
  FigureType: new

- Class: cmd_question
  Output: Try myplot now with an input of 2.
  CorrectAnswer: myplot(2)
  AnswerTests: omnitest(correctExpr='myplot(2)')
  Hint: Type myplot(2) at the command prompt.

- Class: cmd_question
  Output: You can see that the hump of t distribution (in blue) is not as high as the normal's. Consequently, the two tails of the t distribution absorb the extra mass, so they're thicker than the normal's. Note that with 2 degrees of freedom, you only have 3 data points. Ha! Talk about small sample sizes. Now try myplot  with an input of 20.
  CorrectAnswer: myplot(20)
  AnswerTests: omnitest(correctExpr='myplot(20)')
  Hint: Type myplot(20) at the command prompt.

- Class: text
  Output: The two distributions are almost right on top of each other using this higher degree of freedom.

- Class: figure
  Output:  Another way to look at these distributions is to plot their quantiles. From the slides, we've provided a second function for you, myplot2, which does this. It plots a lightblue reference line representing normal quantiles and a black line for the t quantiles. Both plot the quantiles starting at the 50th percentile which is 0 (since the distributions are symmetric about 0) and go to the 99th.
  Figure: tQuant.R
  FigureType: new

- Class: cmd_question
  Output: Try myplot2 now with an argument of 2.
  CorrectAnswer: myplot2(2)
  AnswerTests: omnitest(correctExpr='myplot2(2)')
  Hint: Type myplot2(2) at the command prompt.

- Class: text
  Output: The distance between the two lines represents the difference in sizes between the two sets of intervals. Note the thin horizontal and vertical lines. These represent the .975 quantiles for the t and normal distributions respectively. Anyway, you probably recognized the placement of the vertical at 1.96 from the Asymptotics lesson. 

- Class: cmd_question
  Output: Check the placement of the horizontal now using the R function qt with the arguments .975 for the quantile and 2 for the degrees of freedom (df).
  CorrectAnswer: qt(.975,2)
  AnswerTests: omnitest(correctExpr='qt(.975,2)')
  Hint: Type qt(.975,2) at the command prompt.

- Class: cmd_question
  Output: Now run myplot2 with an argument of 20.
  CorrectAnswer: myplot2(20)
  AnswerTests: omnitest(correctExpr='myplot2(20)')
  Hint: Type myplot2(20) at the command prompt.

- Class: text
  Output: The quantiles are much closer together with the higher degrees of freedom. At the 97.5 percentile though the t quantile is still greater than the normal. Student's Rule!

- Class: text
  Output: So the t-interval is defined as X' +/- t_(n-1)*s/sqrt(n) where t_(n-1) is the relevant quantile. The t interval  assumes that the data are iid normal, though it is robust to this assumption and  works well whenever the distribution of the data is roughly symmetric and mound shaped.

- Class: mult_question
  Output: Our plots showed us that for large degrees of freedom, t quantiles become close to what?
  AnswerChoices: standard normal quantiles; standard abnormal quantiles; very large numbers; very small numbers
  CorrectAnswer: standard normal quantiles
  AnswerTests: omnitest(correctVal='standard normal quantiles')
  Hint: Recall that the larger the degrees of freedom, the more the t distribution looked normal. Smaller degrees of freedom made it look abnormal. 

- Class: text
  Output: Although it's pretty great, the t interval isn't always applicable. For skewed distributions, the spirit of the t interval assumptions (being centered around 0) are violated. There are ways of working around this problem (such as taking logs or using a different summary like the median).
     
- Class: text
  Output: For highly discrete data, like binary, intervals other than the t are available. 

- Class: text
  Output: However, paired observations are often analyzed using the t interval by taking differences between the observations. We'll show you what we mean now.

- Class: text
  Output: We hope you're not tired because we're going to look at some sleep data. This was the data originally analyzed in Gosset's Biometrika paper, which shows the increase in hours for 10 patients on two soporific drugs. 

- Class: cmd_question
  Output: We've loaded the data for you. R treats it as two groups rather than paired. To see what we mean type sleep now. This will show you how the data is stored. 
  CorrectAnswer: sleep
  AnswerTests: omnitest(correctExpr='sleep')
  Hint: Type sleep at the command prompt.

- Class: text
  Output: We see 20 entries, the first 10 show the results (extra) of the first drug (group 1) on each of the patients (ID), and the last 10 entries the results of the second drug (group 2) on each patient (ID). 

- Class: figure
  Output:  Here we've plotted the data in a paired way, connecting each patient's two results with a line, group 1 results on the left and group 2 on the right. See that purple line with the steep slope? That's ID 9, with 0 result for group 1 and 4.6 for group 2. 
  Figure: sleepPlot.R
  FigureType: new

- Class: text
  Output: If  we just looked at the 20 data points we'd be comparing group 1 variations with group 2 variations. Both groups have quite large ranges. However, when we look at the data paired for each patient, we see that the variations in results are usually much smaller and depend on the particular subject. 

- Class: cmd_question
  Output: To clarify, we've defined some variables for you, namely g1 and g2. These are two 10-long vectors, respectively holding the results of the 10 patients for each of the two drugs. Look at the range of g1 using the R command range. 
  CorrectAnswer: range(g1)
  AnswerTests: omnitest(correctExpr='range(g1)')
  Hint: Type range(g1) at the command prompt.

- Class: cmd_question
  Output: So g1 values go from -1.6 to 3.7. Now look at the range of g2. We see that the ranges of both groups are relatively large.
  CorrectAnswer: range(g2)
  AnswerTests: omnitest(correctExpr='range(g2)')
  Hint: Type  range(g2) at the command prompt.

- Class: cmd_question
  Output:  Now let's look at the pairwise difference. We can take advantage of R's componentwise subtraction of vectors and create the vector difference by subtracting g1 from g2. Do this now.
  CorrectAnswer: difference <- g2-g1
  AnswerTests: expr_creates_var("difference"); omnitest(correctExpr='difference <- g2-g1')
  Hint: Type  difference <- g2-g1 at the command prompt.

- Class: cmd_question
  Output:  Now use the R function mean to find the average of difference.
  CorrectAnswer: mean(difference)
  AnswerTests: omnitest(correctExpr='mean(difference)')
  Hint: Type mean(difference) at the command prompt.

- Class: text
  Output: See how much smaller the mean difference in this paired data is compared to the group variations?

- Class: cmd_question
  Output:  Now use the R function sd to find the standard deviation of  difference and put the result in the variable s.
  CorrectAnswer: s <- sd(difference)
  AnswerTests: expr_creates_var("s"); omnitest(correctExpr='s <- sd(difference)')
  Hint: Type s <- sd(difference) at the command prompt.

- Class: cmd_question
  Output:  Now recall the formula for finding the t confidence interval, X' +/- t_(n-1)*s/sqrt(n). Make the appropriate substitutions to find the 95% confidence intervals for the average difference you just computed. We've stored it in the variable mn for you to use here. Remember to use the R construct c(-1,1) for the +/- portion of the formula and the R function qt with .975 and n-1 degrees of freedom for the quantile portion. Our data size is 10.
  CorrectAnswer: mn + c(-1,1)*qt(.975,9)*s/sqrt(10)
  AnswerTests:  omnitest(correctExpr='mn + c(-1,1)*qt(.975,9)*s/sqrt(10)')
  Hint: Type mn + c(-1,1)*qt(.975,9)*s/sqrt(10) at the command prompt.

- Class: cmd_question
  Output:  We could also just have used the R function t.test with the argument difference to get this result. (You can use the default values for all the other arguments.) As with the other R test functions, this returns a lot of information. Since all we're interested in at the moment is the confidence interval we can pick this off with the construct x$conf.int. Try this now.
  CorrectAnswer: t.test(difference)$conf.int
  AnswerTests:  omnitest(correctExpr='t.test(difference)$conf.int')
  Hint: Type t.test(difference)$conf.int at the command prompt.

- Class: video
  Output: As the slides showed,  R provides several ways of using t.test to find the confidence interval of this data. Would you like to see the R code of these alternatives and how to display them nicely? You'll need an internet connection to see it.
  VideoLink: "http://wilcrofter.github.io/slidex/markDown/ttest.html"

- Class: text
  Output: We now present methods, using t confidence intervals, for comparing independent groups. 

- Class: text
  Output: Suppose that we want to compare the mean blood pressure between two groups in a randomized trial. We'll compare those who received the treatment to those who received a placebo. Unlike the sleep study, we cannot use the paired t test because the groups are independent and may have different sample sizes.

- Class: text
  Output: So our goal is to find a 95% confidence interval of the diffence between two population means. Let's represent this difference as mu_y - mu_x. How do we do this? Recall our formula X' +/- t_(n-1)*s/sqrt(n)

- Class: text
  Output: First we need a sample mean, but we have two, X' and Y', one from each group. It makes sense that we'd have to take their difference (Y'-X') as well, since we're looking for a confidence interval that contains the difference mu_y-mu_x. Now we need to specify a t quantile. Suppose the groups have different sizes n_x and n_y. 

- Class: mult_question
  Output: For one group we used the  quantile t_(.975,n-1). What do you think we'll use for the quantile of this problem?
  AnswerChoices: t_(.975,n_x-1); t_(.975,n_y-n_x-2); t_(.975,n_x+n_y-1); t_(.975,n_x+n_y-2)
  CorrectAnswer: t_(.975,n_x+n_y-2)
  AnswerTests: omnitest(correctVal='t_(.975,n_x+n_y-2)')
  Hint: We lose one degree of freedom from each group because we've calculated the sample mean from each group, so we add the two sizes and subtract two. 

- Class: text
  Output: The only term remaining is the standard error which for the single group is s/sqrt(n). Let's deal with the numerator first. Our interval will assume (for now) a common variance s^2 across the two groups. We'll actually pool variance information from the two groups using a weighted sum. (We'll deal with the more complicated situation later.) 

- Class: text
  Output: We call the variance estimator we use the pooled variance S^2. The formula for it requires two variance estimators, one for each group. We multiply each by its respective degrees of freedom and divide the sum by the total number of degrees of freedom. This is how we weight the respective variances; those coming from bigger samples get more weight.

- Class: mult_question
  Output: Which of the following represents the numerator of this expression?
  AnswerChoices: (n_x-1)(S_x)^2+(n_y-1)(S_y)^2; (n_x)(S_x)^2+(n_y)(S_y)^2; (n_x)(S_x)+(n_y)(S_y) 
  CorrectAnswer: (n_x-1)(S_x)^2+(n_y-1)(S_y)^2
  AnswerTests: omnitest(correctVal='(n_x-1)(S_x)^2+(n_y-1)(S_y)^2')
  Hint: We need variances so the choice without the squared S terms is incorrect. Recall that the degrees of freedom is one less than the sample size for each group so that eliminates another choice and only one choice remains.


- Class: mult_question
  Output: Which of the following represents the total number of degrees of freedom?
  AnswerChoices: (n_x-1)+(n_y-1); (n_x+n_y); (n_x+n_y-1); (n_x+n_y+2)
  CorrectAnswer: (n_x-1)+(n_y-1)
  AnswerTests: omnitest(correctVal='(n_x-1)+(n_y-1)')
  Hint: Recall that the degrees of freedom is one less than the sample size for each group. We asked this a few questions ago, though we've put this answer in a different, but equivalent form.

- Class: text
  Output: Now recall we're calculating the standard error term which for the single group case was s/sqrt(n). We've got the numerator done, by pooling the sample variances. How do we handle the 1/sqrt(n) portion? We can simply add 1/n_x and 1/n_y and take the square root of the sum. Then we MULTIPLY this by the sample variance to complete the estimate of the standard error.

- Class: text
  Output: Now we'll plug in some numbers from the slides based on an example from Rosner's book Fundamentals of Biostatistics, a very good, if heavy, reference book. We want to compare blood pressure from two independent groups.  

- Class: cmd_question
  Output: The first is a group of 8 oral contraceptive users and the second is a group of 21 controls. The two means are X'_{oc}=132.86 and X'_{c}=127.44, and the two sample standard deviations are s_{oc}= 15.34 and s_{c}= 18.23. Let's first compute the numerator of the pooled sample variance by weighting the sum of the two by their respective sample sizes. Recall the formula (n_x-1)(S_x)^2+(n_y-1)(S_y)^2 and fill in the values to create a variable sp.
  CorrectAnswer: sp <- 7*15.34^2 + 20*18.23^2
  AnswerTests:  omnitest(correctExpr='sp <- 7*15.34^2 + 20*18.23^2')
  Hint: Type sp <- 7*15.34^2 + 20*18.23^2 at the command prompt. Here 7 and 20 are each one less than the given sample sizes, and 15.34 and 18.23 are the respective standard deviations. We square these to convert them to variances.

- Class: cmd_question
  Output: Now how many degrees of freedom are there? Put your answer in the variable ns.
  CorrectAnswer: ns <- 8+21-2
  AnswerTests:  ANY_of_exprs('ns <- 8+21-2','ns <- 27', 'ns <-21+8-2')
  Hint: Add the two sample sizes and subtract 2. Put the result in ns.

- Class: cmd_question
  Output: Now divide sp by ns, take the square root and put the result back in sp.
  CorrectAnswer: sp <- sqrt(sp/ns)
  AnswerTests:  omnitest(correctExpr='sp <- sqrt(sp/ns)')
  Hint: Type sp <- sqrt(sp/ns) at the command prompt.

- Class: cmd_question
  Output: Now to find the 95% confidence interval. Recall our basic formula X' +/- t_(n-1)*s/sqrt(n) and all the changes we need to make for working with two independent samples. We'll plug in the difference of the sample means for X' and our variable ns for the degrees of freedom when finding the t quantile. For the standard error, we multiply sp  by the square root of the sum 1/n_{oc} + 1/n_{c}. The values for this problem are X'_{oc}=132.86 and X'_{c}=127.44, n_{oc}=8 and n_{c}=21. Be sure to use the R construct c(-1,1) for the +/- portion and the R function qt with the correct percentile and degrees of freedom.
  CorrectAnswer: 132.86-127.44+c(-1,1)*qt(.975,ns)*sp*sqrt(1/8+1/21)
  AnswerTests:  omnitest(correctExpr='132.86-127.44+c(-1,1)*qt(.975,ns)*sp*sqrt(1/8+1/21)')
  Hint: Type 132.86-127.44+c(-1,1)*qt(.975,ns)*sp*sqrt(1/8+1/21) at the command prompt.

- Class: text
  Output: Notice that 0 is contained in this 95% interval. That means that you can't rule out that the means of the two groups are equal since a difference of 0 is in the interval.

- Class: text
  Output: Getting tired? Let's revisit the sleep problem and instead of looking at the data as paired over 10 subjects we'll look at it as two independent sets each of size 10. Recall the data is stored in the two vectors g1 and g2; we've also stored the difference between their means in the variable md. 

- Class: cmd_question
  Output: Let's compute the sample pooled variance and store it in the variable sp. Recall that this is the sqrt(weighted sums of sample variances/deg of freedom). The weight of each is the sample size-1. Use the R function var to compute the variances of  g1 and g2. The degrees of freedom is 10+10-2 = 18.
  CorrectAnswer: sp <- sqrt((9*var(g1)+9*var(g2))/18)
  AnswerTests:  omnitest(correctExpr='sp <- sqrt((9*var(g1)+9*var(g2))/18)')
  Hint: Type sp <- sqrt((9*var(g1)+9*var(g2))/18) at the command prompt.

- Class: cmd_question
  Output: Now  the last term of the formula, the standard error of the mean difference, is simply sp times the square root of the sum 1/10 + 1/10. Find the 95% t confidence interval of the mean difference of the two groups g1 and g2. Substitute md and sp into the formula you used above.
  CorrectAnswer: md + c(-1,1)*qt(.975,18)*sp*sqrt(1/5)
  AnswerTests:  omnitest(correctExpr='md + c(-1,1)*qt(.975,18)*sp*sqrt(1/5)')
  Hint: Type md + c(-1,1)*qt(.975,18)*sp*sqrt(1/5) at the command prompt.

- Class: cmd_question
  Output: We can check this manual calculation against the R function t.test. Since we subtracted g1 from g2, be sure to place g2 as your first argument and g1 as your second. Also make sure the argument paired is FALSE and var.equal is TRUE. We only need the confidence interval so use the construct x$conf.  Do this now.
  CorrectAnswer: t.test(g2,g1,paired=FALSE,var.equal=TRUE)$conf
  AnswerTests:  omnitest(correctExpr='t.test(g2,g1,paired=FALSE,var.equal=TRUE)$conf')
  Hint: Type t.test(g2,g1,paired=FALSE,var.equal=TRUE)$conf at the command prompt.

- Class: cmd_question
  Output: Pretty cool that it matches, right? Note that 0 is again in this 95% interval so you can't reject the claim that the two groups are the same. Let's run t.test again, this time with paired=TRUE and see how different the result is. Don't specify var.equal and look only at the confidence interval.
  CorrectAnswer: t.test(g2,g1,paired=TRUE)$conf
  AnswerTests:  omnitest(correctExpr='t.test(g2,g1,paired=TRUE)$conf')
  Hint: Type t.test(g2,g1,paired=TRUE)$conf at the command prompt.

- Class: text
  Output: See how the interval excludes 0? This means the groups when paired have much different averages.  

- Class: text
  Output: Now let's talk about calculating confidence intervals for two groups which have unequal variances. We won't be pooling them as we did before.

- Class: text
  Output: In this case the formula for the interval is similar to what we saw before, Y'-X' +/- t_df * SE, where as before Y'-X' represents the difference of the sample means. However, the standard error SE and the quantile t_df are calculated differently from previous methods. Here SE is the square root of the sum of the squared standard errors of the two means, (s_1)^2/n_1 + (s_2)^2/n_2 .

- Class: text
  Output: When the underlying X and Y data are iid normal and the variances are different, the normalized statistic we started this lesson with, (X'-mu)/(s/sqrt(n)), doesn't follow a t distribution. However, it can be approximated by a t distribution if we set the degrees of freedom appropriately. 

- Class: text
  Output: The formula for the degrees of freedom is a complicated fraction that no one remembers.  The numerator is the SQUARE of the sum of the squared standard errors of the two sample means. Each has the form s^2/n. The denominator is the sum of two terms, one for each group. Each term has the same form. It is the standard error of the mean raised to the fourth power divided by the sample size-1. More precisely, each term looks like (s^4/n^2)/(n-1). We use this df to find the t quantile.

- Class: video
  Output: Would you like to see this formula nicely displayed? You'll need an internet connection to do this.
  VideoLink: "http://wilcrofter.github.io/slidex/markDown/diffVar.html"

- Class: text
  Output: Let's plug in the numbers from the blood pressure study to see how this works. Recall we have two groups, the first with size 8 and X'_{oc}=132.86 and s_{oc}=15.34 and the second with size 21 and X'_{c}=127.44 and s_{c}=18.23. 

- Class: cmd_question
  Output: Let's compute the degrees of freedom first. Start with the numerator. It's the square of the sum of two terms. Each term is of the form s^2/n. Do this now and put the result in num. Our numbers were 15.34 with size 8 and 18.23 with size 21. 
  CorrectAnswer: num <- (15.34^2/8 + 18.23^2/21)^2
  AnswerTests:  omnitest(correctExpr='num <- (15.34^2/8 + 18.23^2/21)^2')
  Hint: Type  num <- (15.34^2/8 + 18.23^2/21)^2 at the command prompt.

- Class: cmd_question
  Output: Now the denominator. This is the sum of two terms. Each term has the form s^4/n^2/(n-1).  Put the result in the variable den. Our numbers were 15.34 with size 8 and 18.23 with size 21. 
  CorrectAnswer: den <- 15.34^4/8^2/7 + 18.23^4/21^2/20
  AnswerTests:  omnitest(correctExpr='den <- 15.34^4/8^2/7 + 18.23^4/21^2/20')
  Hint: Type  den <- 15.34^4/8^2/7 + 18.23^4/21^2/20 at the command prompt.

- Class: cmd_question
  Output: Now divide num by den and put the result in mydf.
  CorrectAnswer: mydf <- num/den
  AnswerTests:  omnitest(correctExpr='mydf <- num/den')
  Hint: Type  mydf <- num/den at the command prompt.

- Class: cmd_question
  Output: Now with the R function qt(.975,mydf) to compute the 95% t interval. Recall the formula. X'_{oc}-X'_{c} +/- t_df * SE. Recall that SE is the square root of the sum of the squared standard errors of the two means, (s_1)^2/n_1 + (s_2)^2/n_2 . Again our numbers are the following. X'_{oc}=132.86  s_{oc}=15.34  and n_{oc}=8 .  X'_{c}=127.44  s_{c}=18.23  and n_{c}=21. 
  CorrectAnswer: 132.86-127.44 +c(-1,1)*qt(.975,mydf)*sqrt(15.34^2/8 + 18.23^2/21)
  AnswerTests:  omnitest(correctExpr='132.86-127.44 +c(-1,1)*qt(.975,mydf)*sqrt(15.34^2/8 + 18.23^2/21)')
  Hint: Type  132.86-127.44 +c(-1,1)*qt(.975,mydf)*sqrt(15.34^2/8 + 18.23^2/21) at the command prompt.

- Class: text
  Output: R makes things a lot easier. If you call t.test with var.equal set to FALSE, it will do the nasty degrees of freedom calculation for you.


- Class: text
  Output: Congrats! You've concluded this rather t-dious lesson on all things t related - statistics, distributions, intervals. Hope you're not too teed off!

