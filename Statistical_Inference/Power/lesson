- Class: meta
  Course: Statistical_Inference
  Lesson: Power
  Author: Swirl Coders
  Type: Coursera
  Organization: Johns Hopkins Bloomberg School of Public Health
  Version: 2.2.0

- Class: text
  Output: "Power. (Slides for this and other Data Science courses may be found at github https://github.com/DataScienceSpecialization/courses/. If you care to use them, they must be downloaded as a zip file and viewed locally. This lesson corresponds to 06_Statistical_Inference/11_Power.)"

- Class: text
  Output: In this lesson, as the name suggests, we'll discuss POWER, which  is the probability of rejecting the null hypothesis when it is false, which is good and righeous. 

- Class: text
  Output: Hence you want more POWER.

- Class: text
  Output: Power comes into play when you're designing an experiment, and in particular, if you're trying to determine if a null result (failing to reject a null hypothesis) is meaningful. For instance, you might have to determine if your sample size was big enough to yield a meaningful, rather than random, result.

- Class: text
  Output: Power gives you the opportunity to detect if your ALTERNATIVE hypothesis is true. 

- Class: mult_question
  Output: Do you recall the definition of a Type II error (remember that errors are bad)?
  AnswerChoices: Rejecting a true null hypothesis; Accepting a false null hypothesis; Miscalculating a t score; Misspelling the word hypothesis
  CorrectAnswer: Accepting a false null hypothesis
  AnswerTests: omnitest(correctVal='Accepting a false null hypothesis')
  Hint: Remember the courtroom example? Letting a guilty person walk, accepting the null hypothesis of innocence, is a Type II error.

- Class: text
  Output: Beta is the probability of a Type II error, accepting a false null hypothesis;  the complement of this is obviously (1 - beta) which represents the probability of rejecting a false null hypothesis. This is good and this is POWER!

- Class: text
  Output: Recall our previous example involving the Respiratory Distress Index and sleep disturbances. Our null hypothesis H_0 was that mu = 30 and our alternative hypothesis H_a was that mu > 30.
 
- Class: mult_question
  Output: Which of the following expressions represents our test statistic under this null hypothesis? Here X' represents the sample mean, s is the sample std deviation, and n is the sample size. Assume X' follows a t distribution.
  AnswerChoices: (X'-30)/(s/sqrt(n)); X'/(s^2/n); (X'-30)/(s^2/n); 30/(s/sqrt(n))
  CorrectAnswer:  (X'-30)/(s/sqrt(n))
  AnswerTests: omnitest(correctVal='(X'-30)/(s/sqrt(n))')
  Hint:  (X'-30)/(s/sqrt(n)) measures the number of standard errors the sample mean is from the mean hypothesized by H_0.

- Class: mult_question
  Output: In the expression for the test statistic (X'-30)/(s/sqrt(n)) what does (s/sqrt(n)) represent?
  AnswerChoices: a standard error; a standard bearer; a standard variance; a standard sample; a standard measure
  CorrectAnswer:  a standard error
  AnswerTests: omnitest(correctVal='a standard error')
  Hint:  Since (X'-30)/(s/sqrt(n)) measures the number of standard errors the sample mean is from the mean hypothesized by H_0, the denominator is the standard error of the sample mean.

- Class: text
  Output: Suppose we're testing a null hypothesis H_0 with an alpha level of .05. Since H_a proposes that mu > 30, the mean hypothesized by H_0, POWER is the probability that the test statistic is greater than the quantile at 1-alpha or .95. For  simplicity, assume  we're working with normal distributions of which we know the variances and Z scores.

- Class: figure 
  Output: Here's the picture we've used a lot in these lessons. As you know, the shaded portion represents 5% of the area under the curve. If a test statistic fell in this shaded portion we would reject H_0 with probabiity .05 because it is too far from the mean (center) of the distribution hypothesized by H_0. Instead we would favor H_a, that  mu > 30.
  Figure: conf_5pct.R
  FigureType: new

- Class: text 
  Output: You might well ask, "What does this have to do with POWER?" Good question. We'll look at some pictures to show you.

- Class: text 
  Output: First we have to emphasize a key point. The two hypotheses, H_0 and H_a, actually represent two distributions since they're talking about means which are centers of distributions. H_0 says that the sample mean X' is mu_0 (30 in our example) and H_a says that X' has mean mu_a. We're assuming normality and equal variance, say sigma^2/n, for both hypotheses, so under H_0, X'~ N(mu_0, sigma^2/n) and under H_a, X'~ N(mu_a, sigma^2/n).

- Class: figure 
  Output: Here's a picture with the two distributions. We've drawn a vertical line at our favorite spot, at the 95th percentile of the red distribution. To the right of the line lies 5% of the distribution.
  Figure: twoDistros.R
  FigureType: new

- Class: mult_question
  Output: Quick quiz! Which distribution represents H_0?
  AnswerChoices: the red; the blue
  CorrectAnswer:  the red
  AnswerTests: omnitest(correctVal='the red')
  Hint:  The two distributions have the same spread (variance). They differ in their means (centers). Which has a mean equal to that hypothesized by H_0?

- Class: mult_question
  Output: Which distribution represents H_a?
  AnswerChoices: the red; the blue
  CorrectAnswer:  the blue
  AnswerTests: omnitest(correctVal='the blue')
  Hint:  The two distributions have the same spread (variance). They differ in their means (centers). Which has a mean different than that hypothesized by H_0?

- Class: mult_question
  Output: From the picture, what is the mean proposed by H_a?
  AnswerChoices: 30; 28, 32; 36; 
  CorrectAnswer:  32
  AnswerTests: omnitest(correctVal='32')
  Hint:  At what value of mu does does the center (highest point) of the blue distribution fall?

- Class: text
  Output: See how much of the blue distribution lies to the right of that big vertical line? 

- Class: text
  Output: That, my friend, is POWER! 

- Class: text
  Output: It's the area under the blue curve (H_a) to the right of the vertical line. 

- Class: cmd_question
  Output:  We've shamelessly stolen code plotting code from the slides so you can see H_a in action. Let's look at pictures before we delve into the numbers. We've fixed mu_0 at 30, sigma (standard deviation) at 4 and n (sample size) at 16. The function myplot just needs a mean as argument. Run myplot now with an argument of 34 to see what it does.
  CorrectAnswer: myplot(34)
  AnswerTests: omnitest(correctExpr='myplot(34)')
  Hint: Type myplot(34) at the command prompt.

- Class: cmd_question
  Output:  Almost all (100%) of the blue curve is to the right of the line, indicating that if the sample mean were 34, the test is more powerful, i.e., there's a higher probability that the null hypothesis is false. Now try myplot with an argument of 33.3.
  CorrectAnswer: myplot(33.3)
  AnswerTests: omnitest(correctExpr='myplot(33.3)')
  Hint: Type myplot(33.3) at the command prompt.

- Class: cmd_question
  Output:  This isn't as powerful as the test with mu_a=34 but it makes a pretty picture. Now try myplot with an argument of 30.
  CorrectAnswer: myplot(30)
  AnswerTests: omnitest(correctExpr='myplot(30)')
  Hint: Type myplot(30) at the command prompt.

- Class: text
  Output: Uh Oh! Did the red curve disappear? No. it's just under the blue curve. The power now, the area under the blue curve to the right of the line, is exactly 5% or alpha!

- Class: text
  Output: So what did we learn?

- Class: text
  Output: First, power is a function that depends on a specific value of an alternative mean, mu_a, which is any value greater than mu_0, the mean hypothesized by H_0. (Recall that H_a specified mu>30.)

- Class: text
  Output: Second, if mu_a is much bigger than mu_0=30 then the power (probability) is bigger than if mu_a is close to 30. As mu_a approaches 30, the mean under H_0, the power approaches alpha.

- Class: cmd_question
  Output:  Just for fun try myplot with   an argument of 28.
  CorrectAnswer: myplot(28)
  AnswerTests: omnitest(correctExpr='myplot(28)')
  Hint: Type myplot(28) at the command prompt.

- Class: text
  Output: We see that the blue curve has moved to the left of the red, so the area under it, to the right of the line, is less than the 5% under the red curve. This, then is even less powerful and contradicts H_a so it's not worth looking at.

- Class: figure 
  Output: Here's a picture of the power curves for different sample sizes. Again, this uses code "borrowed" from the slides. The alternative means, the mu_a's, are plotted along the horizontal axis and power along the vertical.
  Figure: powerCurve.R
  FigureType: new 

- Class: mult_question
  Output: What does the graph show us about mu_a?
  AnswerChoices: as it gets bigger, it gets more powerful; as it gets bigger, it gets less powerful; power is independent of mu_a
  CorrectAnswer: as it gets bigger, it gets more powerful
  AnswerTests: omnitest(correctVal='as it gets bigger, it gets more powerful')
  Hint: As you move to the right along the horizontal axis, does the line go up or down?

- Class: mult_question
  Output: What does the graph show us about sample size?
  AnswerChoices: as it gets bigger, it gets more powerful; as it gets bigger, it gets less powerful; power is independent of sample size
  CorrectAnswer: as it gets bigger, it gets more powerful
  AnswerTests: omnitest(correctVal='as it gets bigger, it gets more powerful')
  Hint: You have to check the color key. The purple line represents a bigger sample size than the red or blue. This purple line goes up faster than any of the other lines.

- Class: text
  Output: Now back to numbers. Our test for determining rejection of H_0 involved comparing a test statistic, namely Z=(X'-30)/(sigma/sqrt(n)), against some quantile, say Z_95, which depended on our level size alpha (.05 in this case). H_a proposed that mu_a > mu_0, so we tested if Z>Z_95.  This is equivalent to X' > Z_95 * (sigma/sqrt(n)) + 30, right?

- Class: text
  Output: Recall that nifty R function pnorm, which gives us the probability that a value drawn from a normal distribution is greater or less than/equal to a specified quantile argument depending on the flag lower.tail. The function also takes a mean and standard deviation as arguments. 

- Class: text
  Output: Suppose we call pnorm with the quantile   Z_95 * (sigma/sqrt(n)) + 30 and specify mu_a as our mean argument. This would return a probability which we can interpret as POWER. Why?

 Class: figure
  Output: Recall our picture of two distributions. Z_95 * (sigma/sqrt(n)) + 30 represents the point at which our vertical line falls. It's the point on the null distribution at the (1-alpha) level.
  Figure: twoDistros.R
  FigureType: new

- Class: mult_question
  Output: Study this picture. Calling pnorm with Z_95 * (sigma/sqrt(n)) + 30 as the quantile and mu_a, say 32, as the mean and lower.tail=FALSE does what?
  AnswerChoices: returns the area under the blue curve to the right of the line; returns the area under the blue curve to the left of the line; returns the area under the red curve to the right of the line; returns the area under the red curve to the left of the line
  CorrectAnswer: returns the area under the blue curve to the right of the line
  AnswerTests: omnitest(correctVal='returns the area under the blue curve to the right of the line')
  Hint: The argument lower.tail=FALSE is a big clue. It indicates we should look to the right of a line. The mean argument is the second clue. It specifies which distribution (red or blue) to examine. 

- Class: mult_question
  Output: Let's try some examples now. Before we do, what do we know pnorm will return if we specify a quantile less than the mean?
  AnswerChoices: an answer less than .50; an answer dependent on alpha; an answer dependent on beta; an answer greater than 1
  CorrectAnswer: an answer less than .50
  AnswerTests: omnitest(correctVal='an answer less than .50')
  Hint: There are several red herrings in the choices. First pnorm will NEVER return a value greater than 1 because density functions by definition have areas equal to 1. We haven't specified an alpha or beta either. The function pnorm just needs a quantile, mean, standard deviation. By default it looks at the lower tail of the distribution. That leaves one choice.

- Class: cmd_question
  Output: First, define a variable z as qnorm(.95) 
  CorrectAnswer: z <- qnorm(.95)
  AnswerTests: omnitest(correctExpr='z <- qnorm(.95)')
  Hint: Type z <- qnorm(.95) at the command prompt.

- Class: cmd_question
  Output: Run pnorm now with the quantile 30+z, mean=30, and lower.tail=FALSE. We've specified sigma and n so that the standard deviation of the sample mean is 1. 
  CorrectAnswer: pnorm(30+z,mean=30,lower.tail=FALSE)
  AnswerTests: omnitest(correctExpr='pnorm(30+z,mean=30,lower.tail=FALSE)')
  Hint: Type pnorm(30+z,mean=30,lower.tail=FALSE) at the command prompt.

- Class: cmd_question
  Output: That's now surprising, is it? With the mean set to mu_0 the two distributions are the same and power=alpha. Now run pnorm now with the quantile 30+z, mean=32, and lower.tail=FALSE. 
  CorrectAnswer: pnorm(30+z,mean=32,lower.tail=FALSE)
  AnswerTests: omnitest(correctExpr='pnorm(30+z,mean=32,lower.tail=FALSE)')
  Hint: Type pnorm(30+z,mean=32,lower.tail=FALSE) at the command prompt.

- Class: text
  Output: See how this is much more powerful? 64% as opposed to 5%. When the sample mean is quite different from the mean hypothesized by the null hypothesis, the probability of rejecting it when it is false is much higher.

- Class: mult_question
  Output: What do you think the first step is?
  AnswerChoices: Create a null hypothesis; Calculate a test statistic from the data;  Compare the test statistic to a Z or t quantile; Consult your crystal ball
  CorrectAnswer: Create a null hypothesis
  AnswerTests: omnitest(correctVal='Create a null hypothesis')
  Hint: You always have to start with a null hypothesis.

- Class: text
  Output: So we have to begin with a null hypothesis which is a reasoned guess at some distribution of a data summary (a statistic). Recall from the last lesson that the null hypothesis H_0 is a baseline against which we'll measure an alternative hypothesis using the actual observed data.

- Class: mult_question
  Output: So you propose a null hypothesis. What's the next step?
  AnswerChoices:  Calculate a test statistic from the given data;  Compare the test statistic to a Z or t score; Go back to the crystal ball; Reject H_0
  CorrectAnswer: Calculate a test statistic from the given data
  AnswerTests: omnitest(correctVal='Calculate a test statistic from the given data')
  Hint: You need something to compare the value  proposed in H_0 with.

- Class: mult_question
  Output: Now you have a proposed statistic (from your reasoned hypothesis) and a test statistic computed from your gathered data. What's the final step? 
  AnswerChoices:  Calculate a test statistic from the given data;  Compare the test statistic to the hypothetical distribution; Go back to the crystal ball; Reject H_0
  CorrectAnswer: Compare the test statistic to the hypothetical distribution
  AnswerTests: omnitest(correctVal='Compare the test statistic to the hypothetical distribution')
  Hint: You have to compare your calculated value to a hypothetical.

- Class: text
  Output: Your comparison tells you how  "extreme" the test value is toward the alternative hypothesis. The p-value is the probability under the null hypothesis of obtaining evidence as extreme or more extreme than  your test statistic (obtained from your observed data) in the direction of the alternative hypothesis. 

- Class: text 
  Output: So if the p-value is small, then one of two things happens. EITHER H_0 is true and we have observed a rare event (in this unusual test statistic) OR H_0 is false. Let's go through an example.

- Class: text 
  Output: Suppose that you get a t statistic of 2.5 with 15 df testing H_0, (that mu = mu_0) versus an alternative H_a (that mu > mu_0). We want to find the probability of getting a t statistic as large as 2.5.

- Class: cmd_question
  Output: R can help us! We can use the R function pt, the distribution function of the t distribution. This function returns one of two probabilities, EITHER the probability of X > q (if lower.tail is FALSE) OR  X <= q (if lower.tail is TRUE), where q is the first argument, a quantile. Here we'll set q=2.5, df=15, lower.tail=FALSE since H_a says that mu>mu_0. We have to gauge the extremity in the direction of H_a. Run this now.
  CorrectAnswer: pt(2.5, 15, lower.tail=FALSE)
  AnswerTests: omnitest(correctExpr='pt(2.5, 15, lower.tail=FALSE)')
  Hint: Type pt(2.5, 15, lower.tail=FALSE) at the command prompt.

- Class: text 
  Output: This result tells us that, if H_0 were true,  we would see this large a test statistic with probability 1% which is rather a small probability.

- Class: mult_question
  Output: What should we do?
  AnswerChoices:   Reject H_0; Fail to reject H_0; Consult the crystal ball
  CorrectAnswer: Reject H_0
  AnswerTests: omnitest(correctVal='Reject H_0')
  Hint: 1% is less than the usual benchmark of 5%

- Class: text 
  Output: Another way to think about a p-value is as an attained significance level. This is a fancy way of saying that the p-value the smallest value of alpha at which you will reject the null hypothesis.

- Class: text 
  Output: Recall the example from our last lesson in which we computed a test statistic of 2. Our H_0 said that mu_0 = 30 and the alternative H_a that mu > 30. Assume we used a Z test (normal distribution). We rejected the one sided test when alpha was set to 0.05.

- Class: cmd_question
  Output: Why did we reject? Find the quantile associated with this test, that's the place to start. Use qnorm at the 95th percentile. 
  CorrectAnswer: qnorm(.95)
  AnswerTests: omnitest(correctExpr='qnorm(.95)')
  Hint: Type qnorm(.95) at the command prompt.

- Class: figure 
  Output: We rejected H_0 because our data (the test statistic actually) favored H_a. The test statistic 2 (shown by the vertical blue line) falls in the shaded portion of this figure because it exceeds the quantile. As you know, the shaded portion represents 5% of the area under the curve.
  Figure: conf_5pct.R
  FigureType: new

- Class: cmd_question
  Output: Now try the 99th percentile to see if we would still reject H_0. 
  CorrectAnswer: qnorm(.99)
  AnswerTests: omnitest(correctExpr='qnorm(.99)')
  Hint: Type qnorm(.99) at the command prompt.

- Class: mult_question
  Output: Would we reject H_0 if alpha were .01?
  AnswerChoices: Yes; No
  CorrectAnswer: No
  AnswerTests: omnitest(correctVal='No')
  Hint: Now the quantile 2.33 exceeds the test statistic 2.

- Class: figure 
  Output: Again, a picture's worth a thousand words, right? The vertical line at the test statistic 2 is not in the region of rejection.
  Figure: conf_1pct.R
  FigureType: new

- Class: cmd_question
  Output: So our data (the test statistic) tells us what the attained significance level is. We use the R function pnorm to give us this number. With the default values, specifically lower.tail=TRUE, this gives us the probability that a random draw from the distribution is less than or equal to the argument. Try it now with the test statistic value 2. Use the default values for all the other arguments.
  CorrectAnswer: pnorm(2)
  AnswerTests: omnitest(correctExpr='pnorm(2)')
  Hint: Type pnorm(2) at the command prompt.

- Class: text
  Output: Just as we thought, somewhere between .95 (where we rejected) and .99 (where we failed  to reject). That's reassuring.

- Class: cmd_question
  Output: Now let's find the p value associated with this example. As before, we'll use  pnorm. But this time we'll set the lower.tail argument to false. This gives us the probability of X exceeding the test statistic, that is, the area under the curve to the right of test statistic. Try it now with the test statistic value 2. 
  CorrectAnswer: pnorm(2,lower.tail=FALSE)
  AnswerTests: omnitest(correctExpr='pnorm(2,lower.tail=FALSE)')
  Hint: Type pnorm(2,lower.tail=FALSE) at the command prompt.

- Class: text
  Output: This tells us that the attained level of significance is about 2%.

- Class: text
  Output: By reporting a p-value reviewers of your work can perform the hypothesis test at any alpha level they choose. The general rule is that if the p-value is less than the specified alpha you reject the null hypothesis and if it's greater you fail to reject.
 
- Class: text
  Output: For a two sided hypothesis test, you have to double the smaller of the two one-sided  p values. We'll see an example of this shortly. Most software assumes a two-sided test and automatically doubles the p value.
 
- Class: text
  Output: Now for the two-sided test. Recall the binomial example from the last lesson - the family with 8 children, 7 of whom are girls. You want to test H_0, that p=.5, where p is the probability of a girl (like a fair coin flip). H_a is that p is not equal to .5. It's either greater or less than .5. 

- Class: cmd_question
  Output: This is a two-sided test. First we find the probability of having at least i girls, for i running from 0 to 8. We have a vector of these probabilities, mybin. Look at it now.
  CorrectAnswer: mybin
  AnswerTests: omnitest(correctExpr='mybin')
  Hint: Type mybin at the command prompt.

- Class: cmd_question
  Output: The second last value shows us that the probability of having at least 7 girls (out of 8 children) is .035, assuming that genders are equally likely (p=.5).  You can verify this with the R function pbinom, with the arguments 6, size=8, prob=.5, and lower.tail=FALSE. (This last yields the probability that X>6.) Try this now.
  CorrectAnswer: pbinom(6,size=8,prob=.5,lower.tail=FALSE)
  AnswerTests: omnitest(correctExpr='pbinom(6,size=8,prob=.5,lower.tail=FALSE)')
  Hint: Type pbinom(6,size=8,prob=.5,lower.tail=FALSE) at the command prompt.

- Class: mult_question
  Output: We see a probability of about .03. Should we reject or fail to reject H_0 if alpha = .05?
  AnswerChoices: Reject; Fail to reject
  CorrectAnswer: Reject
  AnswerTests: omnitest(correctVal='Reject')
  Hint: Remember the picture of areas. The probability .03 is less than the benchmark of .05. 

- Class: mult_question
  Output: We see a probability of about .03. Should we reject or fail to reject H_0 if alpha = .04?
  AnswerChoices: Reject; Fail to reject
  CorrectAnswer: Reject
  AnswerTests: omnitest(correctVal='Reject')
  Hint: Remember the picture of areas. The probability .03 is less than .04.

- Class: mult_question
  Output: We see a probability of about .03. Should we reject or fail to reject H_0 if alpha = .03?
  AnswerChoices: Reject; Fail to reject
  CorrectAnswer: Fail to reject
  AnswerTests: omnitest(correctVal='Fail to reject')
  Hint: The p-value is about 3.5 which is greater than alpha=.03.

- Class: cmd_question
  Output: For the other side of the test we want the probability that X<=7, again out of a sample of size 8 with probability .5. Again, we use pbinom, this time with an argument of 7 and lower.tail=TRUE. Try this now.
  CorrectAnswer: pbinom(7,size=8,prob=.5,lower.tail=TRUE)
  AnswerTests: omnitest(correctExpr='pbinom(7,size=8,prob=.5,lower.tail=TRUE)')
  Hint: Type pbinom(7,size=8,prob=.5,lower.tail=TRUE) at the command prompt.

- Class: text
  Output: So it's pretty likely (probability .996) that out of 8 children you'll have at most 7 girls. The p value of this two sided test is 2*the smaller of the two one-sided values. In this case the lower value is .035, so 2*.035 is the p-value for this two-sided test. 

- Class: text
  Output: Now a final example using a Poisson distribution. Remember that this is discrete and it involves counts or rates of counts. The example from the slides involves rates of infections in a hospital.

- Class: text
  Output: Suppose that the hospital has an infection rate of 10 infections per 100 person/days at risk. This is a rate of 0.1.  Assume that an infection rate of 0.05 is the benchmark. This is our alpha level, recognize it? With this model, could the observed rate (.1) be larger than the benchmark 0.05 by chance or does it indicate a problem? 

- Class: text
  Output: In other words,  H_0 says that lambda = 0.05 so lambda_0 * 100 = 5, and H_a says that lambda > 0.05. Is H_0 true and our observed rate (.1) is just a fluke OR should we reject H_0 ?

- Class: cmd_question
  Output: As before, R has the handy function ppois, which returns probabilities for Poisson distributions. We want the probability of seeing at least 9 infections using a lambda value of 5 and lower.tail=FALSE. As when we used pbinom we have to use 9 as the argument since we're looking for a probability of a value greater than the argument. Try this now.
  CorrectAnswer: ppois(9,5,lower.tail=FALSE)
  AnswerTests: omnitest(correctExpr='ppois(9,5,lower.tail=FALSE)')
  Hint: Type ppois(9,5,lower.tail=FALSE) at the command prompt.

- Class: mult_question
  Output: We see a probability of about .03. Should we reject or fail to reject H_0? (Remember those helpful pictures with shaded areas. Smaller areas mean smaller probabilities and vice versa.)
  AnswerChoices: Reject; Fail to reject
  CorrectAnswer: Reject
  AnswerTests: omnitest(correctVal='Reject')
  Hint: Remember the picture of areas. The probability .03 is less than the benchmark of .05. 

- Class: text
  Output: So we reject the infection rate hypothesized by H_0 since the data favors H_a, indicating that the rate is much higher. 

- Class: text
  Output: Congrats! You finished this lesson. We hope you p-valued it.
